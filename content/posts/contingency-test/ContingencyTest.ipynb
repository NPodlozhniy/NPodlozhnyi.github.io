{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "id": "riK_HgjhpqSS"
   },
   "source": [
    "---\n",
    "title: \"Mastering Homogeneity hypothesis testing\"\n",
    "summary: \"Why Fisher's Exact test is the relic of the past and Chi-squared is the only one you need\"\n",
    "author: \"Nikita Podlozhniy\"\n",
    "date: \"2024-12-01\"\n",
    "format:\n",
    "    hugo-md:\n",
    "        output-file: \"contingency-test.md\"\n",
    "        html-math-method: katex\n",
    "        code-fold: true\n",
    "jupyter: python3\n",
    "execute:\n",
    "    enabled: false\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QJY4RCVG2M1c"
   },
   "source": [
    "## Contingency Tests Overview\n",
    "\n",
    "**Intro**\n",
    "\n",
    "In the world of statistical analysis, contingency tests play a crucial role in examining the relationship between two categorical variables. These tests are essential tools for researchers across various disciplines, enabling them to determine whether there is a significant correlation between the variables of interest.\n",
    "\n",
    "**Real-world Relevance**\n",
    "\n",
    "To illustrate the practical significance of contingency tests, let's consider a real-world scenario:\n",
    "imagine a market research team is investigating the relationship between customer satisfaction (a few levels e.g. Satisfied, Neutral, Dissatisfied) and the type of product purchased (there are multiple products) from an online marketplace. They collect data from a limited sample of customers who recently made purchases building a contingency table. By applying a contingency test, such as Fisher's exact or Chi-squared test, researchers can determine whether customer satisfaction and the type of product purchased are connected.\n",
    "\n",
    "**Focus**\n",
    "\n",
    "This notebook embarks on a journey to explore the subtleties of Fisher's exact vs. Chi-squared tests application, delving into Fisher's implementation nuances, and performance characteristics. A comparative analysis of two implementations of the Fisher's exact test is covered: one crafted in pure Python and the other leveraging the statistical package of R through the `rpy2` library. Furthermore, we'll scrutinize the performance and accuracy of both approaches, comparing their results and dissecting their respective advantages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZ7Gw_4_202S"
   },
   "source": [
    "## Background: Fisher's Exact and Chi-Squared\n",
    "\n",
    "**Contingency Tables and Statistical Independence**\n",
    "\n",
    "Contingency tables serve as the foundation for these tests, presenting the observed frequencies of different combinations of categories for the two or more variables. By analyzing the distribution of frequencies within the table, contingency tests help to assess whether the observed patterns are likely due to chance or reflect a genuine interconnection between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "fGmk6GIcpqSW"
   },
   "outputs": [],
   "source": [
    "table = [[1, 24, 5], [5, 20, 7], [14, 11, 7], [11, 14, 8], [10, 10, 10], [12, 12, 12]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qk7LR9ElpqSX"
   },
   "source": [
    "### Fisher's Exact\n",
    "\n",
    "Fisher's Exact Test, a non-parametric statistical test, plays a pivotal role in hypothesis testing for categorical data. This test is particularly valuable when dealing with small sample sizes, where the assumptions of the chi-squared test are violated.\n",
    "\n",
    "**Derivation of the Hypergeometric Distribution**\n",
    "\n",
    "The hypergeometric distribution arises from a scenario involving sampling without replacement from a finite population containing two types of objects: \"successes\" and \"failures.\" In the context of contingency tables, these objects correspond to the different categories of the two variables being analyzed.\n",
    "\n",
    "Consider a population of size N, containing K objects classified as \"successes\" and N-K objects classified as \"failures.\" We draw a sample of size n without replacement from this population. The hypergeometric distribution describes the probability of obtaining exactly k successes in the sample.\n",
    "\n",
    "**The Hypergeometric Distribution Formula**\n",
    "\n",
    "The probability mass function of the hypergeometric distribution is given by:\n",
    "\n",
    "$$P(X=k) = \\frac{\\binom{K}{k} \\binom{N-K}{n-k}}{\\binom{N}{n}}$$\n",
    "\n",
    "where:\n",
    "\n",
    "-   N: Total population size\n",
    "-   K: Number of successes in the population\n",
    "-   n: Sample size\n",
    "-   k: Number of successes in the sample\n",
    "\n",
    "**Fisher's Exact Test: Applying the Hypergeometric Distribution**\n",
    "\n",
    "Fisher's Exact Test leverages the hypergeometric distribution to calculate the exact probability of observing a given contingency table, or one more extreme, assuming the null hypothesis of independence between the variables. This exact probability is then used to assess the statistical significance of the observed association.\n",
    "\n",
    "### Chi-Squared\n",
    "\n",
    "The Chi-squared test is another widely used method for analyzing contingency tables to determine whether there is a significant connection between categorical variables. It relies on a statistical approach based on the Chi-squared distribution.\n",
    "\n",
    "**Chi-Squared Statistic: Measuring the Difference**\n",
    "\n",
    "The Chi-squared test calculates a test statistic, denoted by $\\chi^2$, which quantifies the difference between the observed frequencies in the contingency table and the frequencies expected under the null hypothesis of independence. The null hypothesis assumes that there is no association between the variables, meaning that the observed frequencies should be close to the expected frequencies.\n",
    "\n",
    "\n",
    "**Testing the Null Hypothesis**\n",
    "\n",
    "The calculated chi-squared statistic is then compared to the chi-squared distribution with degrees of freedom determined by the dimensions of the contingency table. If the table has $N \\times M$ size then degrees of freedom = $(N-1)(M-1)$\n",
    "\n",
    "\n",
    "**Assumptions and Limitations**\n",
    "\n",
    "Both of these procedures, like any statistical test, operates under certain assumptions which are crucial for ensuring the validity of the test's results.\n",
    "Their common requirements are:\n",
    "\n",
    "1.  **Categorical Data:** The variables being analyzed must be categorical, meaning they can be divided into distinct categories or groups.\n",
    "2.  **Independent Observations:** The observations in the contingency table should be independent of each other. This means that the outcome of one observation should not influence the outcome of another observation.\n",
    "\n",
    "In addition each of them has a third extra requirement\n",
    "\n",
    " - Fisher: **Fixed Margins**\n",
    "\n",
    "> The row and column totals in the contingency table are considered fixed. This implies that the sample sizes for each category are predetermined.\n",
    "\n",
    " - Chi-squared: **Sample sizes**\n",
    "\n",
    "> The expected cell frequencies should be sufficiently large for the chi-squared approximation to be valid\n",
    "\n",
    "Apparently namely the third condition for each is the most challenging.\n",
    "\n",
    "\n",
    "The third assumption for Fisher is quite strict and is not usually satisfied in practice. There are other representatives of exact test's family that are free of this requirement like Boschloo's or Barnard's tests, although they are much more computationally expensive, as they require the nuisance parameters estimation and it's not feasible to implement them for the tables larger than 2x2. So the performance is the main issue of the exact tests and if it's the case then Chi-squared test is advised to be applied instead.\n",
    "\n",
    "\n",
    "For Chi-squared violations of the third assumption can lead to inaccurate results. In such cases, Fisher's exact test is often preferred due to its ability to handle small sample sizes and sparse tables where the chi-squared test's approximations may not hold true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leAnwJ1yzeJe"
   },
   "source": [
    "## Fisher's Exact Test Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqI30IJFYi5O"
   },
   "source": [
    "### Pythonic Fisher NxM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tQjqkdWrkem"
   },
   "source": [
    "As long as widely used python packages for statistics like `scipy` or `statsmodels` don't furnish Fisher's exact test for tables larger than 2x2, here is the author's pure Pythonic implementation for this procedure, to get more details follow the function documentation below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_9SmuEFR_V_q"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def _pvalue(func: object, shape: tuple=(2,2)) -> str:\n",
    "    print(f\"p-value: {func([row[:shape[1]] for row in table[:shape[0]]]):.5f}\")\n",
    "\n",
    "\n",
    "def NxM_Fisher_exact_test(table: list[list]) -> float:\n",
    "    \"\"\"\n",
    "    Performs Fisher's exact test for a contingency table of an arbitrary size.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table: list[list]\n",
    "        contigency matrix M x N\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p-value: float\n",
    "    \"\"\"\n",
    "    num_rows = len(table)\n",
    "    num_cols = len(table[0])\n",
    "\n",
    "    row_sums = [sum(row) for row in table]\n",
    "    col_sums = [sum(table[i][j] for i in range(num_rows)) for j in range(num_cols)]\n",
    "\n",
    "    log_p_constant = (\n",
    "        sum(math.lgamma(x + 1) for x in row_sums)\n",
    "        + sum(math.lgamma(y + 1) for y in col_sums)\n",
    "        - math.lgamma(sum(row_sums) + 1)\n",
    "    )\n",
    "\n",
    "    def calculate_log_probability(matrix):\n",
    "        \"\"\"\n",
    "        Calculates the log-probability of a contingency table n x m.\n",
    "\n",
    "        Fisher's statistic under the truthful null hypothesis has a\n",
    "        hypergeometric distribution of the numbers in the cells of the table.\n",
    "\n",
    "        Therefore the probability of the contingency table follows\n",
    "        hypergeometric probability mass function $C^K_k * C^N-K_n-k / C^N_n$\n",
    "\n",
    "        So, simplifying it's clear that the probability follows:\n",
    "        the product of factorials of total row and total columns counts\n",
    "        divided by the total count factorial and factorials of each cell count.\n",
    "\n",
    "        row_1! x..x row_n! x col_1! x..x col_m! / (cell_11! x..x cell_nm! x total!)\n",
    "\n",
    "        1. As the gamma function satisfies: gamma(n + 1) = n!\n",
    "        and it's computationally more stable- it's used instead of factorials.\n",
    "\n",
    "        2. Making the computations more stable I'm switching from product to sum\n",
    "        using logarithmic probability.\n",
    "\n",
    "        \"\"\"\n",
    "        return log_p_constant - sum(\n",
    "                math.lgamma(cell + 1) for row in matrix for cell in row\n",
    "        )\n",
    "\n",
    "    log_p_obs = calculate_log_probability(table)\n",
    "\n",
    "    p_value = 0\n",
    "\n",
    "    def dfs(matrix: list[list], row_id, col_id, tol=1e-10):\n",
    "        \"\"\"\n",
    "        Recursive deep-first search function\n",
    "\n",
    "        Generates all possible contingency tables and calculates their\n",
    "        log-probability adding up those, that are at least as extreme as\n",
    "        the observed contingency table, to the total p-value\n",
    "\n",
    "        Args:\n",
    "            matrix: A list of lists representing the contingency table\n",
    "            row_id: Row index up to which the table is already filled\n",
    "            col_id: Column index up to which the table is already filled\n",
    "            tol: Maximum absolute log-probability comparison error\n",
    "\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        nonlocal p_value\n",
    "\n",
    "        # Copy is necessary to make recursion working\n",
    "        table = [row.copy() for row in matrix]\n",
    "\n",
    "        # Stopping condition - only the last row and column are left\n",
    "        if row_id == num_rows - 1 and col_id == num_cols - 1:\n",
    "\n",
    "            for i in range(row_id): # fill last column\n",
    "                table[i][col_id] = row_sums[i] - sum(table[i][:col_id])\n",
    "            for j in range(col_id): # fill last row\n",
    "                table[row_id][j] = col_sums[j] - sum(table[i][j] for i in range(row_id))\n",
    "\n",
    "            bottom_right_cell = row_sums[row_id] - sum(table[row_id][:col_id])\n",
    "\n",
    "            if bottom_right_cell < 0:\n",
    "                # Non-reliable table, all cells must be non-negative\n",
    "                return\n",
    "\n",
    "            else:\n",
    "                table[row_id][col_id] = bottom_right_cell\n",
    "                log_p = calculate_log_probability(table)\n",
    "\n",
    "                if log_p <= log_p_obs + tol:\n",
    "                    p_value += math.exp(log_p)\n",
    "\n",
    "                return\n",
    "\n",
    "        # Fill the table until the Stopping condition isn't met\n",
    "        else:\n",
    "\n",
    "            remaining_row_sum = row_sums[row_id] - sum(table[row_id])\n",
    "            remaining_col_sum = col_sums[col_id] - sum(table[i][col_id] for i in range(num_rows))\n",
    "\n",
    "            for k in range(min(remaining_row_sum, remaining_col_sum) + 1):\n",
    "\n",
    "                table[row_id][col_id] = k\n",
    "\n",
    "                if row_id == num_rows - 2 and col_id == num_cols - 2:\n",
    "                    dfs(table, row_id + 1, col_id + 1, tol=tol)\n",
    "                elif row_id == num_rows - 2:\n",
    "                    dfs(table, 0, col_id + 1, tol=tol)\n",
    "                else:\n",
    "                    dfs(table, row_id + 1, col_id, tol=tol)\n",
    "\n",
    "    dfs(matrix=[[0] * num_cols for _ in range(num_rows)], row_id=0, col_id=0)\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcI-RD6Muwp5"
   },
   "source": [
    "While this exact test above is a precise solution, it does have limitations related to the computational intensity of the test, especially when dealing with large contingency tables. As the table size increases, the number of possible arrangements of data grows exponentially, making the calculations more time-consuming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHrcKj60rdc4",
    "outputId": "a5cee95b-2f77-4514-c858-b8e58a2b1dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00014\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "_pvalue(NxM_Fisher_exact_test, shape=(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvWq2WHeZfXV"
   },
   "source": [
    "### R Fisher NxM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hK_4w97KvkPE"
   },
   "source": [
    "Another option that is to use `rpy` bridge from Python to R, this function works for an arbitrary shape of contingency table and unfortunately doesn't have alternatives in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "OcHhssVcZesa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "\n",
    "def R_fisher_exact_test(table: list[list]) -> float:\n",
    "    \"\"\"\n",
    "    Performs exact Fisher's test using R\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table: list[list]\n",
    "        contigency matrix M x N\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p-value: float\n",
    "    \"\"\"\n",
    "\n",
    "    # Enable automatic conversion between NumPy and R arrays\n",
    "    rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "    # Import necessary R package\n",
    "    stats = importr('stats')\n",
    "\n",
    "    # Perform Fisher's test using the R function with more memory to get p-value\n",
    "    result = stats.fisher_test(np.array(table), workspace = 2e9)\n",
    "\n",
    "    # Extract the p-value\n",
    "    p_value = result[0][0]\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXMnbB6CpqSb"
   },
   "source": [
    "Note that the `rpy2` package has native dependencies, what in particular means that, installed R accompanied by the corresponding libraries is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70pobdil8PPY",
    "outputId": "e4a7388b-f806-4b7f-d06e-abe81225e864"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00014\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "_pvalue(R_fisher_exact_test, shape=(3, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KroXTAMatCAR"
   },
   "source": [
    "### Algorithmic Differences: Python vs R\n",
    "\n",
    "While both the Python and R implementations ultimately calculate the p-value for Fisher's Exact Test, they employ distinct algorithms under the hood, each with its own strengths and weaknesses. Understanding these differences is crucial for selecting the most appropriate implementation for a given scenario.\n",
    "\n",
    "**Python:** utilizes a recursive algorithm to enumerate all possible contingency tables that could arise under the null hypothesis. This approach, while conceptually straightforward, can become computationally expensive.\n",
    "\n",
    "**R:** in contrast, it leverages optimized algorithms and data structures that are specifically designed for efficient calculation of Fisher's Exact Test. These algorithms, often implemented in compiled languages, take advantage of advanced numerical techniques and data representations to minimize computational overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-52aBQBUaSD1"
   },
   "source": [
    "### Performance Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvXYJav7wFnr"
   },
   "source": [
    "**Trade-offs and Considerations:**\n",
    "\n",
    "The choice between the Python and R implementations depends on the specific needs of the analysis. For smaller tables, the Python implementation may suffice, offering ease of understanding and implementation. However, as the table size increases, the computational advantages of the R implementation become more pronounced.\n",
    "\n",
    "\n",
    "I suggest we generate random contingency tables with dimensions ranging from 2x2 to 5x5, representing a diverse range of scenarios encountered in real-world applications. For each table size, we will measure the execution time required by both the Python and R implementations to calculate the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HS_jlyAni9EN",
    "outputId": "0d70d9e9-5fc9-4ac1-9951-3c74199aaf2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00014\n",
      "p-value: 0.00012\n",
      "p-value: 0.00085\n",
      "CPU times: user 745 ms, sys: 7.96 ms, total: 753 ms\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_pvalue(NxM_Fisher_exact_test, shape=(3, 2))\n",
    "_pvalue(NxM_Fisher_exact_test, shape=(4, 2))\n",
    "_pvalue(NxM_Fisher_exact_test, shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xHSW8WGUsilh",
    "outputId": "e9ab9352-0c8a-4590-da58-de2063c32942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00014\n",
      "p-value: 0.00012\n",
      "p-value: 0.00085\n",
      "CPU times: user 2.6 s, sys: 219 ms, total: 2.82 s\n",
      "Wall time: 2.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_pvalue(R_fisher_exact_test, shape=(3, 2))\n",
    "_pvalue(R_fisher_exact_test, shape=(4, 2))\n",
    "_pvalue(R_fisher_exact_test, shape=(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmHmFFwF94BK",
    "outputId": "5704d858-97fd-4360-934e-7f2621efef36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00149\n",
      "CPU times: user 1.46 s, sys: 97 ms, total: 1.55 s\n",
      "Wall time: 1.88 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_pvalue(R_fisher_exact_test, shape=(4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jai8begl91CH",
    "outputId": "8db80710-b80a-4e0d-c665-d9e51026215a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.00149\n",
      "CPU times: user 8min, sys: 921 ms, total: 8min 1s\n",
      "Wall time: 8min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_pvalue(NxM_Fisher_exact_test, shape=(4, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWeYJQ2N-r9h"
   },
   "source": [
    "For sizes more than 2 x 5 and 3 x 3, R package function can significantly outperform the Python counterpart, whereas with tables of less size pure Python function is shining.\n",
    "\n",
    "The results of the benchmarks revealed a clear trend: Python implementation is beaten in terms of execution time for larger tables. As the table dimensions increased, the performance gap between the two implementations is widened drastically. This observation aligns with the algorithmic differences discussed earlier, where the optimized algorithms and data structures employed by the R implementation proved to be more efficient.\n",
    "\n",
    "As a rule of thumb I propose to apply R if $N \\times M > 10$, otherwise Python is preferable and what is more - it doesn't have any dependencies on non-native packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUo4w3JytQE0"
   },
   "source": [
    "### Accuracy Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNpZZYsiymOG"
   },
   "source": [
    "Along with the performance let's assure that the p-values generated by both methods are equivalent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OVsOF-c8wDQc",
    "outputId": "bd7ccb0f-5d07-4e82-dbf6-1c4c91cd8efe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2), false positives: 0.020 ± 0.026\n",
      "shape: (2, 4), false positives: 0.030 ± 0.030\n",
      "shape: (3, 3), false positives: 0.030 ± 0.030\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import multinomial\n",
    "\n",
    "from statsmodels.stats.proportion import proportion_confint\n",
    "\n",
    "P = np.arange(.1, .35, .05)\n",
    "n = 40\n",
    "\n",
    "rv = multinomial(n, P)\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "tol = 1e-5\n",
    "alpha = 0.05\n",
    "n_iterations = 100\n",
    "\n",
    "\n",
    "for shape in [(2, 2), (2, 4), (3, 3)]:\n",
    "\n",
    "    false_positives = 0\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        contingency_table = rv.rvs(shape[0])\n",
    "\n",
    "        p_value_py = NxM_Fisher_exact_test([row[:shape[1]] for row in contingency_table])\n",
    "        p_value_r = R_fisher_exact_test([row[:shape[1]] for row in contingency_table])\n",
    "\n",
    "        if abs(p_value_py - p_value_r) > tol:\n",
    "            print(f\"Different p-values! Python: {p_value_py}, R: {p_value_r}\")\n",
    "            break\n",
    "        elif p_value_py <= alpha:\n",
    "            false_positives += 1\n",
    "\n",
    "    l, r = proportion_confint(count=false_positives, nobs=n_iterations, alpha=0.10, method='wilson')\n",
    "    print(f\"shape: {shape}, false positives: {false_positives/n_iterations:.3f} ± {(r - l) / 2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfCPOnadzlp2"
   },
   "source": [
    "So, it's clear from multiple iterations for different tables and sizes that there is no a single case of different p-values, so the equivalence is practically evident. In addition I've checked Type I error level, it's well below the bound of 5%, which means that ideologically the criterions are valid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-AEcATLtFH8"
   },
   "source": [
    "### Performance Analysis: A Comparative Benchmark\n",
    "\n",
    "\n",
    "As the textbooks say, Fisher's Exact Test stands out as a particularly versatile option when dealing with small sample sizes or sparse contingency tables. It provides accurate p-values, even when the assumptions of other commonly used test, such as the chi-squared test, might be violated. This benefit makes Fisher's Exact test an invaluable method when working with limited data or situations where the chi-squared test's approximation is not applicable.\n",
    "\n",
    "I offer you a procedure to challenge these statements, namely to call the power of the exact test out, when chi-squared assumptions are not satisfied. First we will check the correctness of these two methods and then the power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAj77S0wD0Ft"
   },
   "outputs": [],
   "source": [
    "def chi_squared_challenge(\n",
    "    shape: tuple = (2, 2),\n",
    "    n_iterations: int=1_000,\n",
    "    alpha: float=0.05,\n",
    "    aa_test: bool=True\n",
    ") -> None:\n",
    "\n",
    "    for i in range(1 + len(rv.rvs()[0]) - shape[1]):\n",
    "\n",
    "        fisher_positives = 0\n",
    "        chi2_positives = 0\n",
    "        chi2_yates_positives = 0\n",
    "\n",
    "        zero_expected_count = 0\n",
    "\n",
    "        less_than_5 = 0\n",
    "        less_than_10 = 0\n",
    "\n",
    "        for _ in range(n_iterations):\n",
    "\n",
    "            contingency_table = rv.rvs(shape[0])[:, i:i+shape[1]]\n",
    "\n",
    "            if not aa_test:\n",
    "                contingency_table[0] = contingency_table[0] ** 2\n",
    "\n",
    "            if np.min(contingency_table) == 0:\n",
    "                zero_expected_count += 1\n",
    "                continue\n",
    "\n",
    "            less_than_5 += np.max(np.array(contingency_table) < 5)\n",
    "            less_than_10 += np.max(np.array(contingency_table) < 10)\n",
    "\n",
    "            if shape == (2, 2):\n",
    "                p_value_fisher = fisher_exact(contingency_table).pvalue\n",
    "                p_value_chi2_yates = chi2_contingency(contingency_table, correction=True).pvalue\n",
    "                if p_value_chi2_yates <= alpha:\n",
    "                    chi2_yates_positives += 1\n",
    "            else:\n",
    "                p_value_fisher = NxM_Fisher_exact_test(contingency_table)\n",
    "            p_value_chi2 = chi2_contingency(contingency_table, correction=False).pvalue\n",
    "\n",
    "\n",
    "            if p_value_chi2 <= alpha:\n",
    "                chi2_positives += 1\n",
    "            if p_value_fisher <= alpha:\n",
    "                fisher_positives += 1\n",
    "\n",
    "        valid_tables = n_iterations - zero_expected_count\n",
    "\n",
    "        print(\n",
    "            f\"\\nIf out of {valid_tables} valid {shape[0]}x{shape[1]} tables \"\n",
    "            f\"(w/o zero expected count) number of tables with less than:\"\n",
    "            f\"\\n - 5 elements in any cell is {less_than_5}\"\n",
    "            f\"\\n - 10 elements in any cell is {less_than_10}\"\n",
    "            f\"\\n Then p-values are:\"\n",
    "        )\n",
    "\n",
    "        l, r = proportion_confint(count=fisher_positives, nobs=valid_tables, alpha=0.10, method='wilson')\n",
    "        print(f\"Fisher positives: {fisher_positives/valid_tables:.3f} ± {(r - l) / 2:.3f}\")\n",
    "\n",
    "        l, r = proportion_confint(count=chi2_positives, nobs=valid_tables, alpha=0.10, method='wilson')\n",
    "        print(f\"Chi2 positives: {chi2_positives/valid_tables:.3f} ± {(r - l) / 2:.3f}\")\n",
    "\n",
    "        if not shape == (2, 2):\n",
    "            continue\n",
    "\n",
    "        l, r = proportion_confint(count=chi2_yates_positives, nobs=valid_tables, alpha=0.10, method='wilson')\n",
    "        print(f\"Chi2 Yates positives: {chi2_yates_positives/valid_tables:.3f} ± {(r - l) / 2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oXleOPt9pqSf"
   },
   "source": [
    "According to frequently encountered requirements in the literature regarding expected cell counts for chi-squared test application, a common rule is at least 5 (some requires 10) in all cells of 2x2 table, and 5 or more in 80% of cells in larger tables, but no cells with zero expected count. Furthermore, when the assumption for 2x2 table is not met, Yates's correction is applied.\n",
    "\n",
    "Now, we will check the feasibility of these conditions for 2x2 tables first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqpSwgfm1Uzv"
   },
   "source": [
    "#### Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eyx0hOrk3EqJ",
    "outputId": "7f1e2ffc-8830-4afa-d852-c113c4317003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If out of 969 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 915\n",
      " - 10 elements in any cell is 969\n",
      " Then p-values are:\n",
      "Fisher positives: 0.019 ± 0.007\n",
      "Chi2 positives: 0.043 ± 0.011\n",
      "Chi2 Yates positives: 0.011 ± 0.006\n",
      "\n",
      "If out of 993 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 566\n",
      " - 10 elements in any cell is 993\n",
      " Then p-values are:\n",
      "Fisher positives: 0.024 ± 0.008\n",
      "Chi2 positives: 0.050 ± 0.011\n",
      "Chi2 Yates positives: 0.015 ± 0.006\n",
      "\n",
      "If out of 1000 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 178\n",
      " - 10 elements in any cell is 993\n",
      " Then p-values are:\n",
      "Fisher positives: 0.032 ± 0.009\n",
      "Chi2 positives: 0.052 ± 0.012\n",
      "Chi2 Yates positives: 0.022 ± 0.008\n",
      "\n",
      "If out of 1000 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 27\n",
      " - 10 elements in any cell is 831\n",
      " Then p-values are:\n",
      "Fisher positives: 0.033 ± 0.009\n",
      "Chi2 positives: 0.049 ± 0.011\n",
      "Chi2 Yates positives: 0.022 ± 0.008\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "chi_squared_challenge(aa_test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rf3SLdQt5auu"
   },
   "source": [
    "#### Power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N1jiK8bXqKeN",
    "outputId": "88939c76-2ed9-490a-81ec-ba5cc4240739"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If out of 969 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 785\n",
      " - 10 elements in any cell is 969\n",
      " Then p-values are:\n",
      "Fisher positives: 0.300 ± 0.024\n",
      "Chi2 positives: 0.359 ± 0.025\n",
      "Chi2 Yates positives: 0.265 ± 0.023\n",
      "\n",
      "If out of 993 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 373\n",
      " - 10 elements in any cell is 987\n",
      " Then p-values are:\n",
      "Fisher positives: 0.325 ± 0.024\n",
      "Chi2 positives: 0.370 ± 0.025\n",
      "Chi2 Yates positives: 0.295 ± 0.024\n",
      "\n",
      "If out of 1000 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 90\n",
      " - 10 elements in any cell is 897\n",
      " Then p-values are:\n",
      "Fisher positives: 0.334 ± 0.025\n",
      "Chi2 positives: 0.363 ± 0.025\n",
      "Chi2 Yates positives: 0.305 ± 0.024\n",
      "\n",
      "If out of 1000 valid 2x2 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 9\n",
      " - 10 elements in any cell is 586\n",
      " Then p-values are:\n",
      "Fisher positives: 0.351 ± 0.025\n",
      "Chi2 positives: 0.387 ± 0.025\n",
      "Chi2 Yates positives: 0.327 ± 0.024\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "chi_squared_challenge(aa_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Djk-UQbCE0g"
   },
   "source": [
    "Surprise! In this example it's shown there is no need for Yates nor for Fisher's exact test at all! Chi-squared test doesn't inflate the number of Type I errors and keep the power at least as high as it's for the exact test regardless of the number of cells with low frequencies.\n",
    "\n",
    "JFYI: Some other exact tests might be applied instead of Fisher's test, e.g. Boschloo's test provides higher power but it's a) much slower and b) yet worse than a plain chi-squared, you may prove it on your own as an exercise. Hint: there is a function `boschloo_exact` in `scipy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOxE1jG1uUho"
   },
   "source": [
    "Okay, it' clear with 2x2, but what if the table is getting bigger?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "VxAbSgXhuWOa",
    "outputId": "99fc3af8-1ffd-4ff6-d4a8-ec25b815f4ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If out of 969 valid 2x4 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 804\n",
      " - 10 elements in any cell is 969\n",
      " Then p-values are:\n",
      "Fisher positives: 0.685 ± 0.025\n",
      "Chi2 positives: 0.688 ± 0.024\n",
      "\n",
      "If out of 993 valid 2x4 tables (w/o zero expected count) number of tables with less than:\n",
      " - 5 elements in any cell is 388\n",
      " - 10 elements in any cell is 993\n",
      " Then p-values are:\n",
      "Fisher positives: 0.666 ± 0.025\n",
      "Chi2 positives: 0.672 ± 0.024\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(26)\n",
    "\n",
    "chi_squared_challenge(shape=(2, 4), aa_test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v8qhWfn-Ni8q"
   },
   "source": [
    "The power values are not statistically distinguishable, so chi-squared is still the winner as it's much simpler in calculations and for the data model that I specified it seems that it can handle small table sizes - it takes low values at least as good as Fisher's test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzhL7hnm1nQ2"
   },
   "source": [
    "#### Monte-Carlo Simulation Results Interpretation\n",
    "\n",
    "I'd like to make an extra note that Monte-Carlo simulations can provide valuable insights into the performance and behavior of statistical tests, but it's essential to interpret their results with caution and awareness of their limitations.\n",
    "\n",
    "\n",
    "While simulations can mimic real-world scenarios, they are inherently limited by the assumptions and parameters used in their design. They may not capture the full complexity of real-world data and may not be generalizable to all situations. Therefore, it's crucial to consider the specific context and limitations of the simulation when interpreting its results.\n",
    "\n",
    "\n",
    "Saying that I must admit that I don't have an intention to prove that there is no need for exact tests in any experiment design, I'd rather invite you to challenge your data and your experiments set up specifics, as there is a chance that you will find that chi-squared test is all you need for contingency experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI813hoHCgY_"
   },
   "source": [
    "### Justification for Fisher's Exact over Chi-Squared\n",
    "\n",
    "Even when the chi-squared test appears to perform well in Monte-Carlo simulations, there are compelling theoretical and practical reasons to prefer Fisher's Exact Test in specific situations. Understanding these justifications is crucial for making informed decisions about which test to apply.\n",
    "\n",
    "\n",
    "1.   Sparse Table: Chi-squared test relies on approximations that may not hold true when dealing with sparse contingency tables.\n",
    "2.   Sample Size: Chi-squared test is based on the asymptotic distribution of the test statistic, which assumes that the sample size is large.\n",
    "3.   Effect Size: Chi-squared may be less sensitive in detecting the small effect size, because the approximation may not be as accurate.\n",
    "\n",
    "\n",
    "So, once again: in order to guarantee that you don't have a need for exact tests in your data model setting, you must consciously simulate your data distributions (especially when it comes to sparse tables, small sample sizes and small effect sizes) and then make a decision, the process that I presented here is based on the data my team is exposed to most and hopefully it might be easily simulated with Multinomial distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdT1xv-C9hkn"
   },
   "source": [
    "## General Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07uOrVqO9jfP"
   },
   "source": [
    "Finally I'd like to offer you a full pipeline on how to organize contingency tests efficiently: when Fisher's exact test shall be applied and when Chi-squared is just enough.\n",
    "\n",
    "As you know, exact tests could take time and what I want to achieve is to have a control over the time that I allocate to the function execution.\n",
    "\n",
    "There are a few ways to implement timeouts, my favourite one is leveraging `multiprocessing` capabilities, however it's not always the case that you can run a subprocess under your main process in production, so another concise way to apply timeouts will be shown via `func_timeout` library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_WWhtsjfOFB"
   },
   "source": [
    "### Concurrent Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84WI9ozdpqSn"
   },
   "source": [
    "Simple decorator to pass the output from the subprocess into main process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pcbVp_j5fPty"
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from functools import wraps\n",
    "from multiprocessing import Queue, Process\n",
    "\n",
    "def subprocess_output(procedure: object, queue: Optional[Queue]=None) -> object:\n",
    "\n",
    "    @wraps(procedure)\n",
    "    def wrapper(*args, **kwargs):\n",
    "\n",
    "        p_value = procedure(*args, **kwargs)\n",
    "        queue.put(p_value)\n",
    "\n",
    "        return p_value\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "def concurrent_test(\n",
    "    method: object,\n",
    "    table: list[list],\n",
    "    name: str=\"NxM Fisher's exact test\",\n",
    "    timeout: int=10,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Runs the given method in a separate process with a timeout.\n",
    "    If the process takes longer than the timeout, it is terminated.\n",
    "    The result is returned from the main process.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    method: object\n",
    "        The method to be run in a separate process.\n",
    "    table: list[list]\n",
    "        Contingency matrix M x N\n",
    "    name: str\n",
    "        Process name\n",
    "    timeout: int\n",
    "        Time limit for subprocess execution\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    p-value: float\n",
    "    \"\"\"\n",
    "    queue = Queue()\n",
    "    procedure = subprocess_output(method, queue)\n",
    "    p = Process(\n",
    "        target=procedure,\n",
    "        args=(table,),\n",
    "        name=name\n",
    "    )\n",
    "    p.start()\n",
    "    p.join(timeout=timeout)\n",
    "    p.terminate()\n",
    "    if p.exitcode is not None:\n",
    "        p_value = queue.get()\n",
    "        return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wqtNPx6pYnPW"
   },
   "source": [
    "### Timeout Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHhIZygQpqSo"
   },
   "source": [
    "Handy function that is a good solution if a timeout is the only thing you want to get from a subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VdrMEIuCmGTE"
   },
   "outputs": [],
   "source": [
    "# pip install func-timeout\n",
    "from func_timeout import func_timeout, FunctionTimedOut\n",
    "\n",
    "\n",
    "def timeout_test(\n",
    "    method: object,\n",
    "    table: np.ndarray,\n",
    "    timeout: int=10,\n",
    ") -> float:\n",
    "\n",
    "    try:\n",
    "        p_value = func_timeout(timeout, method, args=(table,))\n",
    "    except FunctionTimedOut:\n",
    "        p_value = None\n",
    "\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvPjkgocuGll"
   },
   "source": [
    "By the way: there is no need for timeout when running `scipy` Fisher's exact test, so it's applied only to those methods analyzed in the chapter above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btJIscFqt5GL",
    "outputId": "42cd4220-0646-4eba-c2e5-19dda4c453bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 14 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SignificanceResult(statistic=1.0416666666666667, pvalue=0.10488212218194087)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "fisher_exact(np.array([[10000, 4000], [12000, 5000]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rc-_DzCL_uz2"
   },
   "source": [
    "### Universal procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKadb3y9ACb_"
   },
   "source": [
    "#### Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOYgoYQHNWme"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, fisher_exact\n",
    "\n",
    "\n",
    "def _contingency_test(table: np.ndarray, criterion: str, timeout: int) -> dict:\n",
    "    \"\"\"\n",
    "    Performs a test of independence of variables in a contingency table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table: np.ndarray\n",
    "        Contingency matrix M x N\n",
    "    criterion: str\n",
    "        Test to be performed\n",
    "    timeout: int\n",
    "        Time limit for Fisher's exact test\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: {\n",
    "        \"method\": str,\n",
    "        \"p-value\": float,\n",
    "        \"error\": str (optional)\n",
    "    }\n",
    "    \"\"\"\n",
    "    if criterion not in {\"chi-squared\", \"fisher-exact\", \"textbook\"}:\n",
    "        raise ValueError(\n",
    "            \"Incorrect type of criterion, \"\n",
    "            \"should be one of the following: 'chi-squared', 'fisher-exact', 'textbook'\"\n",
    "        )\n",
    "\n",
    "    # No timeout if \"fisher-exact\" criterion is set\n",
    "    timeout = timeout + 10_000 * (criterion == \"fisher-exact\")\n",
    "\n",
    "    result = dict.fromkeys([\"method\", \"p-value\"])\n",
    "\n",
    "    try:\n",
    "        if criterion == \"textbook\" and table.shape == (2, 2) and (table >= 10).all():\n",
    "            result[\"method\"] = \"2x2 Pearson's chi-squared test with Yates\"\n",
    "            test = chi2_contingency(table, correction=True)\n",
    "            result[\"p-value\"] = test.pvalue\n",
    "        elif criterion != \"chi-squared\" and table.shape == (2, 2):\n",
    "            result[\"method\"] = \"2x2 Fisher's exact test in Python\"\n",
    "            test = fisher_exact(table)\n",
    "            result[\"p-value\"] = test.pvalue\n",
    "        elif criterion == \"chi-squared\" or (criterion == \"textbook\" and np.sum(table >= 5) >= np.size(table) * 0.80):\n",
    "            result[\"method\"] = \"NxM Pearson's chi-squared test w/o Yates\"\n",
    "            test = chi2_contingency(table, correction=False)\n",
    "            result[\"p-value\"] = test.pvalue\n",
    "        else: # try Exact fisher test if doesn't take too much\n",
    "            if np.size(table) > 10:\n",
    "                name = \"NxM Fisher's exact test in R\"\n",
    "                p_value = timeout_test(\n",
    "                    R_fisher_exact_test, table, timeout\n",
    "                )\n",
    "            else:\n",
    "                name = \"NxM Fisher's exact test in Python\"\n",
    "                p_value = timeout_test(\n",
    "                    NxM_Fisher_exact_test, table, timeout\n",
    "                )\n",
    "            result[\"method\"] = name\n",
    "            if p_value:\n",
    "                result[\"p-value\"] = p_value\n",
    "            else:\n",
    "                result[\"method\"] = \" \".join([\n",
    "                    result[\"method\"],\n",
    "                    \"timed out.\",\n",
    "                    \"NxM Pearson's chi-squared test approximation applied\"\n",
    "                ])\n",
    "                test = chi2_contingency(table, correction=False)\n",
    "                result[\"p-value\"] = test.pvalue\n",
    "\n",
    "    except Exception as error:\n",
    "        result[\"error\"] = f\"{error}\"\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMbxEAHVpqSp"
   },
   "source": [
    "Here is a quick example of how it works with the identified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15H0QEBzoD8C",
    "outputId": "f0095f1f-d7b4-4431-ec0b-bf4929f670ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': \"NxM Pearson's chi-squared test w/o Yates\",\n",
       " 'p-value': 0.00032439327665678783}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.array([row[:2] for row in table[:5]])\n",
    "\n",
    "_contingency_test(t, 'textbook', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzLWK7DNl5gd"
   },
   "source": [
    "#### Input validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7iSrQDy5yOPU"
   },
   "source": [
    "Adding a validation is an important step to prevent end-users from inference the function in the wrong way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "SUQ-0ngGbwv_"
   },
   "outputs": [],
   "source": [
    "def _validate_input(table: list[list]) -> np.array:\n",
    "\n",
    "    try:\n",
    "        array = np.array(table)\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            \"Contingency table's rows must be of equal length.\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        array = array.astype(dtype=int)\n",
    "    except ValueError:\n",
    "        raise ValueError(\n",
    "            \"All cells must contain integer numbers.\"\n",
    "        )\n",
    "\n",
    "    if array.ndim != 2:\n",
    "        raise ValueError(\n",
    "            \"Contigency table must be a 2-dimensional array.\"\n",
    "        )\n",
    "\n",
    "    if (array < 0).any():\n",
    "        raise ValueError(\n",
    "            \"All cells must contain non-negative numbers.\"\n",
    "        )\n",
    "\n",
    "    if array.shape[0] == 2 and np.max(np.min(array, axis=1)) == 0:\n",
    "        raise ValueError(\n",
    "            \"There are cells with zero expected count. \"\n",
    "            \"Expectations must contain only positive numbers.\"\n",
    "        )\n",
    "\n",
    "    return array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnwTG6_AAVzC"
   },
   "source": [
    "#### Put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJajZAevbroa"
   },
   "outputs": [],
   "source": [
    "def general_contingency_test(table: list[list], criterion='textbook', timeout: int=10) -> dict:\n",
    "    \"\"\"\n",
    "    Performs a test of independence of variables in a contingency table\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    table: list[list]\n",
    "        matrix M x N,\n",
    "        where M is the number of compared groups and N is the set of measures\n",
    "    timeout: int\n",
    "        Time limit for Fisher's exact test,\n",
    "        if the calculation takes longer chi-squared test is applied instead\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict: {\n",
    "        \"method\": str,\n",
    "        \"p-value\": float,\n",
    "        \"error\": str (optional)\n",
    "    }\n",
    "    \"\"\"\n",
    "    return _contingency_test(_validate_input(table), criterion, timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sd_0D3oopqSr"
   },
   "source": [
    "Now when we have a general procedure, let's take a look at a few examples of the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIbJFkv6WhD0",
    "outputId": "60a35cec-76b5-460d-e54d-3a7204364110"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': \"NxM Pearson's chi-squared test w/o Yates\",\n",
       " 'p-value': 0.0020940807559433087}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_contingency_test(table, criterion='chi-squared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sxzythrw3Z7R",
    "outputId": "b718d8ef-e0a9-416a-a1ab-38342c1ab23a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': \"NxM Fisher's exact test in R timed out. NxM Pearson's chi-squared test approximation applied\",\n",
       " 'p-value': 5.060441099877772e-17}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "general_contingency_test([[1, 2, 3, 5, 6, 100, 2000], [4, 5, 6, 7, 8, 150, 1000]], timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xsbcU64mpcU1"
   },
   "source": [
    "## The logic wrapped into the library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoQWcYavA423"
   },
   "source": [
    "Good news for you, you don't need to repeat all the code that was shared above as it's already a part of the public Python package `podlozhnyy_module` that comes hande every time you have data analysis assignments at work.\n",
    "\n",
    "**Key Features of the Library:**\n",
    "\n",
    "-   **Automatic Test Selection:** By default, the library automatically selects the most appropriate test based on textbook rules, considering factors such as sample size and expected cell frequencies. This intelligent selection process ensures the validity and accuracy of the results.\n",
    "-   **Flexibility and Control:** Users have the flexibility to override the automatic selection and force the library to apply a specific test if desired. This feature is particularly useful when researchers have prior knowledge or preferences regarding the test to be used.\n",
    "-   **User-Friendly Interface:** The library's interface is designed to be intuitive and easy to use, enabling researchers to effortlessly perform contingency tests without extensive coding or technical expertise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNTK9o5fomid",
    "outputId": "a9b18532-9ffa-43ab-c9ed-72ced1c21a47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey! You've successfully imported the module featured by https://github.com/NPodlozhniy\n",
      "To check the entire set of methods, execute dir(podlozhnyy_module). Enjoy!\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "#| output: false\n",
    "# !pip install podlozhnyy-module==2.6-alpha\n",
    "\n",
    "import podlozhnyy_module as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WVXiDaUpqSs"
   },
   "source": [
    "Library's application is as simple as the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_U0U4ZKosPf",
    "outputId": "6af3c8d0-054d-4115-def2-331c5940d1d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': \"NxM Fisher's exact test in R\", 'p-value': 0.0011288225617825118}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "pm.contingency.general_contingency_test(table[:5], criterion='fisher-exact', timeout=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0_uRtcLYo3qI",
    "outputId": "e92caf04-1032-4906-e12b-2c9cbe4c08bd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'method': \"NxM Fisher's exact test in Python\",\n",
       " 'p-value': 0.0008451539443552633}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "pm.contingency.general_contingency_test(table[:3], criterion='fisher-exact', timeout=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMW2Fbdy2T3-"
   },
   "source": [
    "## Conclusion: A Unified Framework for Contingency Tests\n",
    "\n",
    "This notebook has explored various aspects of contingency tests, with a particular focus on Fisher's Exact Test comparison to Chi-squared test. As a part of the journey we have contrasted the Python and R implementations of the Fisher's test, highlighting their strengths and weaknesses in terms of performance, accuracy, and computational considerations.\n",
    "\n",
    "The powerful framework of Monte-Carlo simulations is provided to enable the readers to simulate their data and ultimately apply proper testing techniques in their field providing the accurate guidance to the business.\n",
    "\n",
    "**podlozhnyy\\_module** library: a flexible solution\n",
    "\n",
    "The code presented in this notebook has been thoughtfully integrated into the `podlozhnyy_module` library, offering a flexible and user-friendly solution for conducting contingency tests. This library empowers users to select the most appropriate test based on textbook rules or to override the default behavior and force the application of a specific test, such as Fisher's Exact or the Chi-squared test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3mY9sbTd2UsM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
